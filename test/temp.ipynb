{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Boxes: 360\n",
      "Len Boxes: 352\n",
      "Len Boxes: 351\n",
      "Len Boxes: 350\n",
      "Len Boxes: 332\n",
      "Len Boxes: 326\n",
      "Len Boxes: 302\n",
      "Len Boxes: 272\n",
      "Len Boxes: 190\n",
      "Len Boxes: 148\n",
      "Len Boxes: 111\n",
      "Len Boxes: 79\n",
      "Len Boxes: 72\n",
      "Len Boxes: 69\n",
      "Len Boxes: 67\n",
      "Len Boxes: 63\n",
      "Len Boxes: 36\n",
      "Len Boxes: 20\n",
      "Len Boxes: 16\n",
      "Len Boxes: 13\n",
      "Len Boxes: 12\n",
      "Len Boxes: 8\n",
      "Len Boxes: 6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# tuplify\n",
    "def tup(point):\n",
    "    return (point[0], point[1]);\n",
    "\n",
    "# returns true if the two boxes overlap\n",
    "def overlap(source, target):\n",
    "    # unpack points\n",
    "    tl1, br1 = source;\n",
    "    tl2, br2 = target;\n",
    "\n",
    "    # checks\n",
    "    if (tl1[0] >= br2[0] or tl2[0] >= br1[0]):\n",
    "        return False;\n",
    "    if (tl1[1] >= br2[1] or tl2[1] >= br1[1]):\n",
    "        return False;\n",
    "    return True;\n",
    "\n",
    "# returns all overlapping boxes\n",
    "def getAllOverlaps(boxes, bounds, index):\n",
    "    overlaps = [];\n",
    "    for a in range(len(boxes)):\n",
    "        if a != index:\n",
    "            if overlap(bounds, boxes[a]):\n",
    "                overlaps.append(a);\n",
    "    return overlaps;\n",
    "\n",
    "img = cv2.imread(\"Images/1.png\")\n",
    "orig = np.copy(img);\n",
    "blue, green, red = cv2.split(img)\n",
    "\n",
    "def medianCanny(img, thresh1, thresh2):\n",
    "    median = np.median(img)\n",
    "    img = cv2.Canny(img, int(thresh1 * median), int(thresh2 * median))\n",
    "    return img\n",
    "\n",
    "blue_edges = medianCanny(blue, 0, 1)\n",
    "green_edges = medianCanny(green, 0, 1)\n",
    "red_edges = medianCanny(red, 0, 1)\n",
    "\n",
    "edges = blue_edges | green_edges | red_edges\n",
    "\n",
    "# I'm using OpenCV 3.4. This returns (contours, hierarchy) in OpenCV 2 and 4\n",
    "contours,hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL ,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# go through the contours and save the box edges\n",
    "boxes = []; # each element is [[top-left], [bottom-right]];\n",
    "hierarchy = hierarchy[0]\n",
    "for component in zip(contours, hierarchy):\n",
    "    currentContour = component[0]\n",
    "    currentHierarchy = component[1]\n",
    "    x,y,w,h = cv2.boundingRect(currentContour)\n",
    "    if currentHierarchy[3] < 0:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        boxes.append([[x,y], [x+w, y+h]]);\n",
    "\n",
    "# filter out excessively large boxes\n",
    "filtered = [];\n",
    "max_area = 30000;\n",
    "for box in boxes:\n",
    "    w = box[1][0] - box[0][0];\n",
    "    h = box[1][1] - box[0][1];\n",
    "    if w*h < max_area:\n",
    "        filtered.append(box);\n",
    "boxes = filtered;\n",
    "\n",
    "# go through the boxes and start merging\n",
    "merge_margin = 15;\n",
    "\n",
    "# this is gonna take a long time\n",
    "finished = False;\n",
    "highlight = [[0,0], [1,1]];\n",
    "points = [[[0,0]]];\n",
    "while not finished:\n",
    "    # set end con\n",
    "    finished = True;\n",
    "\n",
    "    # check progress\n",
    "    print(\"Len Boxes: \" + str(len(boxes)));\n",
    "\n",
    "    # draw boxes # comment this section out to run faster\n",
    "    copy = np.copy(orig);\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(copy, tup(box[0]), tup(box[1]), (0,200,0), 1);\n",
    "    cv2.rectangle(copy, tup(highlight[0]), tup(highlight[1]), (0,0,255), 2);\n",
    "    for point in points:\n",
    "        point = point[0];\n",
    "        cv2.circle(copy, tup(point), 4, (255,0,0), -1);\n",
    "    cv2.imshow(\"Copy\", copy);\n",
    "    key = cv2.waitKey(1);\n",
    "    if key == ord('q'):\n",
    "        break;\n",
    "\n",
    "    # loop through boxes\n",
    "    index = len(boxes) - 1;\n",
    "    while index >= 0:\n",
    "        # grab current box\n",
    "        curr = boxes[index];\n",
    "\n",
    "        # add margin\n",
    "        tl = curr[0][:];\n",
    "        br = curr[1][:];\n",
    "        tl[0] -= merge_margin;\n",
    "        tl[1] -= merge_margin;\n",
    "        br[0] += merge_margin;\n",
    "        br[1] += merge_margin;\n",
    "\n",
    "        # get matching boxes\n",
    "        overlaps = getAllOverlaps(boxes, [tl, br], index);\n",
    "        \n",
    "        # check if empty\n",
    "        if len(overlaps) > 0:\n",
    "            # combine boxes\n",
    "            # convert to a contour\n",
    "            con = [];\n",
    "            overlaps.append(index);\n",
    "            for ind in overlaps:\n",
    "                tl, br = boxes[ind];\n",
    "                con.append([tl]);\n",
    "                con.append([br]);\n",
    "            con = np.array(con);\n",
    "\n",
    "            # get bounding rect\n",
    "            x,y,w,h = cv2.boundingRect(con);\n",
    "\n",
    "            # stop growing\n",
    "            w -= 1;\n",
    "            h -= 1;\n",
    "            merged = [[x,y], [x+w, y+h]];\n",
    "\n",
    "            # highlights\n",
    "            highlight = merged[:];\n",
    "            points = con;\n",
    "\n",
    "            # remove boxes from list\n",
    "            overlaps.sort(reverse = True);\n",
    "            for ind in overlaps:\n",
    "                del boxes[ind];\n",
    "            boxes.append(merged);\n",
    "\n",
    "            # set flag\n",
    "            finished = False;\n",
    "            break;\n",
    "\n",
    "        # increment\n",
    "        index -= 1;\n",
    "cv2.destroyAllWindows();\n",
    "\n",
    "# show final\n",
    "copy = np.copy(orig);\n",
    "for box in boxes:\n",
    "    cv2.rectangle(copy, tup(box[0]), tup(box[1]), (0,200,0), 1);\n",
    "cv2.imshow(\"Final\", copy);\n",
    "cv2.waitKey(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': [1, 2, 3, 4, 5, 2, 3, 4, 5, 5, 5, 5, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 3, 4, 5, 5, 2, 3, 4, 5, 5, 2, 3, 4, 5, 5], 'page_num': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'block_num': [0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16], 'par_num': [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1], 'line_num': [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1], 'word_num': [0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 3, 4, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 1, 2, 3, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 1, 2, 3, 4, 5, 6, 7, 0, 0, 1, 2, 3, 4, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2], 'left': [0, 47, 47, 47, 47, 298, 298, 298, 298, 349, 410, 480, 507, 560, 560, 560, 560, 31, 31, 31, 31, 44, 44, 44, 44, 686, 686, 686, 686, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 36, 36, 36, 36, 129, 224, 265, 283, 303, 341, 347, 403, 528, 627, 36, 36, 36, 133, 224, 332, 350, 410, 452, 528, 628, 36, 36, 36, 133, 224, 290, 332, 528, 628, 676, 36, 36, 36, 64, 224, 251, 273, 333, 529, 575, 36, 36, 36, 78, 133, 36, 36, 36, 65, 134, 224, 254, 332, 421, 505, 528, 628, 726, 36, 36, 36, 134, 224, 332, 421, 528, 628, 726, 36, 36, 36, 62, 134, 224, 250, 332, 421, 447, 529, 628, 651, 726, 36, 36, 36, 86, 97, 260, 295, 348, 385, 484, 495, 655, 690, 742, 779, 36, 36, 36, 74, 271, 360, 414, 424, 462, 673, 761, 36, 36, 36, 277, 367, 412, 424, 688, 765, 36, 36, 36, 86, 277, 367, 36, 36, 36, 63, 270, 359, 411, 421, 448, 760, 421, 421, 442, 753, 416, 416, 416, 416, 31, 31, 31, 31, 36, 36, 36, 36, 56, 81, 122, 160, 184, 237, 261, 307, 349, 381, 36, 36, 64, 99, 132, 151, 189, 217, 237, 260, 36, 36, 36, 36, 82, 332, 332, 332, 332, 382, 627, 627, 627, 627, 676], 'top': [0, 64, 64, 64, 64, 69, 69, 69, 70, 70, 69, 69, 69, 119, 119, 119, 119, 194, 194, 194, 194, 239, 239, 239, 239, 234, 234, 234, 234, 261, 261, 261, 261, 279, 279, 279, 279, 513, 513, 513, 513, 109, 109, 109, 122, 112, 121, 121, 121, 120, 122, 120, 120, 109, 118, 135, 135, 139, 138, 138, 137, 136, 136, 136, 136, 135, 151, 151, 156, 155, 154, 156, 153, 152, 152, 151, 160, 160, 172, 172, 171, 171, 177, 160, 169, 171, 188, 188, 189, 189, 188, 201, 201, 206, 206, 205, 205, 204, 203, 203, 193, 202, 202, 201, 226, 226, 229, 228, 238, 227, 237, 226, 236, 235, 243, 243, 245, 255, 245, 254, 254, 244, 254, 253, 243, 253, 252, 252, 269, 269, 272, 272, 272, 271, 271, 270, 270, 270, 270, 269, 269, 269, 269, 275, 275, 289, 289, 277, 287, 277, 287, 286, 275, 285, 292, 292, 305, 304, 303, 293, 303, 292, 302, 320, 320, 322, 322, 321, 320, 521, 521, 524, 524, 522, 522, 512, 522, 522, 521, 538, 539, 539, 538, 263, 263, 263, 263, 548, 548, 548, 548, 556, 556, 556, 558, 557, 557, 557, 557, 557, 557, 557, 556, 556, 556, 574, 575, 575, 574, 574, 574, 574, 574, 574, 574, 592, 592, 592, 592, 592, 590, 590, 590, 590, 591, 589, 589, 589, 589, 590], 'width': [822, 143, 143, 143, 143, 230, 230, 230, 47, 57, 66, 21, 21, 5, 5, 5, 5, 776, 776, 776, 776, 16, 16, 16, 16, 10, 10, 10, 10, 775, 775, 775, 775, 775, 775, 775, 775, 774, 774, 774, 774, 764, 640, 640, 38, 16, 38, 15, 16, 33, 1, 53, 23, 31, 49, 637, 637, 59, 43, 29, 12, 56, 38, 58, 35, 45, 701, 701, 30, 7, 61, 1, 44, 69, 44, 61, 541, 541, 24, 14, 23, 17, 1, 71, 42, 2, 152, 152, 38, 20, 55, 741, 741, 25, 22, 26, 26, 46, 27, 71, 20, 52, 70, 51, 741, 741, 10, 20, 20, 21, 13, 21, 51, 51, 711, 711, 22, 16, 20, 19, 18, 21, 19, 17, 24, 7, 22, 21, 764, 764, 46, 7, 88, 31, 21, 33, 95, 7, 58, 32, 21, 33, 21, 763, 763, 34, 27, 45, 44, 5, 30, 29, 38, 38, 762, 762, 28, 39, 38, 7, 28, 21, 33, 369, 369, 46, 49, 39, 38, 762, 762, 23, 43, 45, 45, 7, 23, 55, 38, 376, 17, 12, 44, 1, 1, 1, 1, 775, 775, 775, 775, 367, 367, 367, 16, 21, 37, 34, 20, 49, 20, 42, 39, 28, 22, 314, 24, 31, 29, 14, 28, 25, 16, 13, 90, 57, 57, 57, 42, 11, 61, 61, 61, 46, 11, 60, 60, 60, 45, 11], 'height': [623, 13, 13, 13, 13, 10, 10, 10, 9, 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 8, 10, 10, 10, 10, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 439, 31, 31, 11, 28, 10, 8, 8, 9, 2, 8, 8, 28, 9, 14, 14, 10, 9, 8, 8, 9, 9, 9, 8, 8, 13, 13, 8, 8, 10, 6, 9, 11, 8, 9, 28, 28, 9, 8, 8, 8, 2, 28, 8, 6, 13, 13, 12, 8, 9, 15, 15, 10, 8, 8, 10, 8, 9, 9, 28, 9, 9, 9, 31, 31, 28, 28, 8, 28, 8, 28, 8, 9, 30, 30, 28, 9, 28, 9, 9, 28, 8, 9, 28, 8, 9, 8, 14, 14, 11, 8, 8, 8, 8, 9, 9, 8, 8, 9, 8, 8, 8, 30, 30, 8, 8, 28, 8, 28, 8, 9, 28, 8, 28, 28, 9, 8, 9, 28, 8, 28, 8, 12, 12, 10, 8, 8, 9, 27, 13, 8, 10, 9, 9, 28, 9, 8, 9, 10, 9, 8, 9, 290, 290, 290, 290, 5, 5, 5, 5, 27, 27, 12, 8, 11, 11, 11, 9, 9, 8, 8, 11, 9, 11, 9, 8, 8, 9, 9, 9, 9, 8, 8, 8, 10, 10, 10, 8, 10, 11, 11, 11, 11, 10, 11, 11, 11, 9, 10], 'conf': [-1, -1, -1, -1, 8, -1, -1, -1, 0, 95, 96, 96, 96, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 85, 53, 63, 96, 96, 92, 92, 96, 76, 38, 28, -1, -1, 47, 13, 93, 92, 82, 89, 87, 66, 65, -1, -1, 93, 81, 62, 90, 94, 79, 30, 88, -1, -1, 89, 89, 91, 76, 76, 86, 88, 87, -1, -1, 91, 69, 0, -1, -1, 84, 84, 90, 62, 62, 65, 0, 0, 27, 44, 0, -1, -1, 68, 90, 62, 82, 90, 94, 11, 76, -1, -1, 68, 80, 89, 86, 86, 93, 85, 80, 20, 72, 72, 91, -1, -1, 93, 93, 75, 71, 68, 42, 80, 93, 78, 63, 45, 61, 95, -1, -1, 0, 88, 64, 50, 92, 88, 81, 75, 69, -1, -1, 92, 85, 92, 89, 34, 90, 61, -1, -1, 77, 78, 88, 82, -1, -1, 77, 59, 0, 0, 94, 94, 62, 63, -1, 83, 86, 64, -1, -1, -1, 95, -1, -1, -1, 95, -1, -1, -1, 60, 93, 76, 96, 96, 96, 96, 96, 96, 92, 58, -1, 52, 94, 96, 96, 66, 87, 85, 73, 80, -1, -1, -1, 49, 96, -1, -1, -1, 85, 96, -1, -1, -1, 45, 75], 'text': ['', '', '', '', 'OMTPECE', '', '', '', '(OMTECH', 'CHEMICAL', 'INDUSTRIES', 'PVT.', 'LTD.', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', 'PaySlip', '62', 'Payslip', 'for', 'the', 'month', ':', 'December', '2018', 'Branel', 'ANDHERI', '', '', 'EmpCode:', ' TOM102', 'Name', 'Mr.', 'VIRENORA', 'VITHAL', 'KOLBEKAR', 'Basic:', '12750.00', '', '', 'Grade', 'A', 'Department', ':', 'EXPORT', 'Designation:', 'EXPORT', 'EXECUTIVE', '', '', 'ESIC', 'No.', 'UAN', 'No.', ':', '100409628642', 'Division', ':', '', '', 'Joining', 'Dt:', '01/04/2018', '', '', 'Days', 'Paid', '28.00', 'Days', 'Present:', '23.00', 'WoOffiPdOn:', '—_', '4.00/0.00', 'LWP/Absent:', '_0.00/3.00', '', '', 'si', '1.00', 'cL:', '0.00', 'PL', '0.00', 'co+ico', '0.00/0.00', '', '', 'Bal.', 'SL:', '0.00', 'Bal.', 'CL:', '0.00', 'Bal.', 'PL:', '4.00', 'Bal.', 'CO:', '0.00', '', '', 'Earnings', '&', 'Reimbursements', 'Gross', 'Amt', 'Actual', 'Amt_[Deductions', '&', 'Recoveries', 'Gross', 'Amt', 'Actual', 'Amt', '', '', '‘Famed', 'Basic', '12750.00', '11516.00\"', '|', 'PROV.', 'FUND.', '4530.00', '1382.00', '', '', 'HRA', '7275.00', '6571.00', '|', 'PTax', '0.00', '200.00', '', '', 'Transport', 'Allowance', '6275.00', '5668.00', '', '', 'Total', 'Earnings', '726300.00', '723755.00', '|', 'Total', 'Deductions', '1582.00', '', 'Not', 'Pa', '2173.00', '', '', '', ' ', '', '', '', ' ', '', '', '', '‘Nat', 'Pay:', 'Rupees', 'Twenty', 'Two', 'Thousand', 'One', 'Hundred', 'Seventy', 'Three', 'Only', '', 'Bank', 'Name:', 'BANK', 'OF', 'INDIA.', 'Bank', 'Alc', 'No.', '011610100005311', '', '', '', 'Checked', 'by:', '', '', '', 'Approved', 'by:', '', '', '', 'Received', 'by:']}\n"
     ]
    }
   ],
   "source": [
    "images = cv2.imread(\"1.png\")\n",
    "rgb = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
    "results = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: OMTPECE\n",
      "conf: 8\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: (OMTECH\n",
      "conf: 0\n",
      "text: CHEMICAL\n",
      "conf: 95\n",
      "text: INDUSTRIES\n",
      "conf: 96\n",
      "text: PVT.\n",
      "conf: 96\n",
      "text: LTD.\n",
      "conf: 96\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: PaySlip\n",
      "conf: 85\n",
      "text: 62\n",
      "conf: 53\n",
      "text: Payslip\n",
      "conf: 63\n",
      "text: for\n",
      "conf: 96\n",
      "text: the\n",
      "conf: 96\n",
      "text: month\n",
      "conf: 92\n",
      "text: :\n",
      "conf: 92\n",
      "text: December\n",
      "conf: 96\n",
      "text: 2018\n",
      "conf: 76\n",
      "text: Branel\n",
      "conf: 38\n",
      "text: ANDHERI\n",
      "conf: 28\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: EmpCode:\n",
      "conf: 47\n",
      "text:  TOM102\n",
      "conf: 13\n",
      "text: Name\n",
      "conf: 93\n",
      "text: Mr.\n",
      "conf: 92\n",
      "text: VIRENORA\n",
      "conf: 82\n",
      "text: VITHAL\n",
      "conf: 89\n",
      "text: KOLBEKAR\n",
      "conf: 87\n",
      "text: Basic:\n",
      "conf: 66\n",
      "text: 12750.00\n",
      "conf: 65\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Grade\n",
      "conf: 93\n",
      "text: A\n",
      "conf: 81\n",
      "text: Department\n",
      "conf: 62\n",
      "text: :\n",
      "conf: 90\n",
      "text: EXPORT\n",
      "conf: 94\n",
      "text: Designation:\n",
      "conf: 79\n",
      "text: EXPORT\n",
      "conf: 30\n",
      "text: EXECUTIVE\n",
      "conf: 88\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: ESIC\n",
      "conf: 89\n",
      "text: No.\n",
      "conf: 89\n",
      "text: UAN\n",
      "conf: 91\n",
      "text: No.\n",
      "conf: 76\n",
      "text: :\n",
      "conf: 76\n",
      "text: 100409628642\n",
      "conf: 86\n",
      "text: Division\n",
      "conf: 88\n",
      "text: :\n",
      "conf: 87\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Joining\n",
      "conf: 91\n",
      "text: Dt:\n",
      "conf: 69\n",
      "text: 01/04/2018\n",
      "conf: 0\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Days\n",
      "conf: 84\n",
      "text: Paid\n",
      "conf: 84\n",
      "text: 28.00\n",
      "conf: 90\n",
      "text: Days\n",
      "conf: 62\n",
      "text: Present:\n",
      "conf: 62\n",
      "text: 23.00\n",
      "conf: 65\n",
      "text: WoOffiPdOn:\n",
      "conf: 0\n",
      "text: —_\n",
      "conf: 0\n",
      "text: 4.00/0.00\n",
      "conf: 27\n",
      "text: LWP/Absent:\n",
      "conf: 44\n",
      "text: _0.00/3.00\n",
      "conf: 0\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: si\n",
      "conf: 68\n",
      "text: 1.00\n",
      "conf: 90\n",
      "text: cL:\n",
      "conf: 62\n",
      "text: 0.00\n",
      "conf: 82\n",
      "text: PL\n",
      "conf: 90\n",
      "text: 0.00\n",
      "conf: 94\n",
      "text: co+ico\n",
      "conf: 11\n",
      "text: 0.00/0.00\n",
      "conf: 76\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Bal.\n",
      "conf: 68\n",
      "text: SL:\n",
      "conf: 80\n",
      "text: 0.00\n",
      "conf: 89\n",
      "text: Bal.\n",
      "conf: 86\n",
      "text: CL:\n",
      "conf: 86\n",
      "text: 0.00\n",
      "conf: 93\n",
      "text: Bal.\n",
      "conf: 85\n",
      "text: PL:\n",
      "conf: 80\n",
      "text: 4.00\n",
      "conf: 20\n",
      "text: Bal.\n",
      "conf: 72\n",
      "text: CO:\n",
      "conf: 72\n",
      "text: 0.00\n",
      "conf: 91\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Earnings\n",
      "conf: 93\n",
      "text: &\n",
      "conf: 93\n",
      "text: Reimbursements\n",
      "conf: 75\n",
      "text: Gross\n",
      "conf: 71\n",
      "text: Amt\n",
      "conf: 68\n",
      "text: Actual\n",
      "conf: 42\n",
      "text: Amt_[Deductions\n",
      "conf: 80\n",
      "text: &\n",
      "conf: 93\n",
      "text: Recoveries\n",
      "conf: 78\n",
      "text: Gross\n",
      "conf: 63\n",
      "text: Amt\n",
      "conf: 45\n",
      "text: Actual\n",
      "conf: 61\n",
      "text: Amt\n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: ‘Famed\n",
      "conf: 0\n",
      "text: Basic\n",
      "conf: 88\n",
      "text: 12750.00\n",
      "conf: 64\n",
      "text: 11516.00\"\n",
      "conf: 50\n",
      "text: |\n",
      "conf: 92\n",
      "text: PROV.\n",
      "conf: 88\n",
      "text: FUND.\n",
      "conf: 81\n",
      "text: 4530.00\n",
      "conf: 75\n",
      "text: 1382.00\n",
      "conf: 69\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: HRA\n",
      "conf: 92\n",
      "text: 7275.00\n",
      "conf: 85\n",
      "text: 6571.00\n",
      "conf: 92\n",
      "text: |\n",
      "conf: 89\n",
      "text: PTax\n",
      "conf: 34\n",
      "text: 0.00\n",
      "conf: 90\n",
      "text: 200.00\n",
      "conf: 61\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Transport\n",
      "conf: 77\n",
      "text: Allowance\n",
      "conf: 78\n",
      "text: 6275.00\n",
      "conf: 88\n",
      "text: 5668.00\n",
      "conf: 82\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Total\n",
      "conf: 77\n",
      "text: Earnings\n",
      "conf: 59\n",
      "text: 726300.00\n",
      "conf: 0\n",
      "text: 723755.00\n",
      "conf: 0\n",
      "text: |\n",
      "conf: 94\n",
      "text: Total\n",
      "conf: 94\n",
      "text: Deductions\n",
      "conf: 62\n",
      "text: 1582.00\n",
      "conf: 63\n",
      "text: \n",
      "conf: -1\n",
      "text: Not\n",
      "conf: 83\n",
      "text: Pa\n",
      "conf: 86\n",
      "text: 2173.00\n",
      "conf: 64\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text:  \n",
      "conf: 95\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: ‘Nat\n",
      "conf: 60\n",
      "text: Pay:\n",
      "conf: 93\n",
      "text: Rupees\n",
      "conf: 76\n",
      "text: Twenty\n",
      "conf: 96\n",
      "text: Two\n",
      "conf: 96\n",
      "text: Thousand\n",
      "conf: 96\n",
      "text: One\n",
      "conf: 96\n",
      "text: Hundred\n",
      "conf: 96\n",
      "text: Seventy\n",
      "conf: 96\n",
      "text: Three\n",
      "conf: 92\n",
      "text: Only\n",
      "conf: 58\n",
      "text: \n",
      "conf: -1\n",
      "text: Bank\n",
      "conf: 52\n",
      "text: Name:\n",
      "conf: 94\n",
      "text: BANK\n",
      "conf: 96\n",
      "text: OF\n",
      "conf: 96\n",
      "text: INDIA.\n",
      "conf: 66\n",
      "text: Bank\n",
      "conf: 87\n",
      "text: Alc\n",
      "conf: 85\n",
      "text: No.\n",
      "conf: 73\n",
      "text: 011610100005311\n",
      "conf: 80\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Checked\n",
      "conf: 49\n",
      "text: by:\n",
      "conf: 96\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Approved\n",
      "conf: 85\n",
      "text: by:\n",
      "conf: 96\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: \n",
      "conf: -1\n",
      "text: Received\n",
      "conf: 45\n",
      "text: by:\n",
      "conf: 75\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(results[\"text\"])):\n",
    "      \n",
    "    # We can then extract the bounding box coordinates\n",
    "    # of the text region from  the current result\n",
    "    # x = results[\"left\"][i]\n",
    "    # y = results[\"top\"][i]\n",
    "    # w = results[\"width\"][i]\n",
    "    # h = results[\"height\"][i]\n",
    "      \n",
    "    # We will also extract the OCR text itself along\n",
    "    # with the confidence of the text localization\n",
    "    text = results[\"text\"][i]\n",
    "    conf = int(results[\"conf\"][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:35\u001b[1;36m\u001b[0m\n\u001b[1;33m    if (y1-y2)==0:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "image = cv2.imread('temp/bounding/bounding_roi_0.png')\n",
    "# cv2.imshow()\n",
    "cv2.imshow(\"txt\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use canny edge detection\n",
    "edges = cv2.Canny(gray,50,150,apertureSize=3)\n",
    "\n",
    "# Apply HoughLinesP method to\n",
    "# to directly obtain line end points\n",
    "lines_list =[]\n",
    "lines = cv2.HoughLinesP(\n",
    "\t\t\tedges, # Input edge image\n",
    "\t\t\t1, # Distance resolution in pixels\n",
    "\t\t\tnp.pi/180, # Angle resolution in radians\n",
    "\t\t\tthreshold=100, # Min number of votes for valid line\n",
    "\t\t\tminLineLength=5, # Min allowed length of line\n",
    "\t\t\tmaxLineGap=10 # Max allowed gap between line for joining them\n",
    "\t\t\t)\n",
    "\n",
    "# Iterate over points\n",
    "for points in lines:\n",
    "\t# Extracted points nested in the list\n",
    "\tx1,y1,x2,y2=points[0]\n",
    "\t# Draw the lines joing the points\n",
    "\t# On the original image\n",
    "if (y1-y2)==0:\n",
    "\tcv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\t# Maintain a simples lookup list for points\n",
    "\tlines_list.append([(x1,y1),(x2,y2)])\n",
    "\t\n",
    "# Save the result image\n",
    "cv2.imwrite('detectedLines.png',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/2.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    if i==0:\n",
    "        continue\n",
    "\n",
    "    epsilon = 0.01*cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    cv2.drawContours(img, contour, 0, (0,0,0), 4)\n",
    "    x,y,w,h = cv2.boundingRect(approx)\n",
    "\n",
    "    x_mid = int(x+(w/3))\n",
    "    y_mid = int(y+(h/1.5))\n",
    "\n",
    "    coords = (x_mid, y_mid)\n",
    "    color = (0,0,0)\n",
    "    # font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "    # if len(approx)==4:\n",
    "        # cv2.putText(img, \"Quadrilateral\", coords, font, 1, color, 1)\n",
    "\n",
    "cv2.imshow(\"shapes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Af? Situry WP\n",
      "\n",
      "tn Words t Rupets Sixty Seven Thousand Three Hundred Seventy Seven only:\n",
      "\n",
      "Notes Site thts @ 2 tormttepanttted stuttrrgnt t doesnot nsed mtty etanature,,\n",
      "\n",
      "ge ste\n",
      "\n",
      "TEL HOME FINANCE LiMttED\n",
      "\n",
      "_Devsu om rte Wir er 2bHt\n",
      "Eenpttyes Netre PRASHANT RANSTTRUMAR SABUIMALA — Enptoyee Gode | O1ABSYS\n",
      "Datignation 7 SALES MANAGER Laeetien, 3 SURAT\n",
      "Departrtant + SALES Jen Date UBIO TE\n",
      "‘PAN Nurtibtr ASUPSasbOS PF anetunt No, .\n",
      "‘Brant SURAT MING ROAD ‘Butig Att, No, DBMTSOLOSLAS\n",
      "Berk Name ‘HOFe ornde + MANAGER\n",
      "Ne, Dionne Days, 30.50 ‘Leane Teen 2 8888\n",
      "‘UANND : wwe 70080\n",
      "ESCNO .\n",
      "\n",
      "EARWINGS if DEDUCTIONS\n",
      "BASIC SALARY 2300400 [PROFESSION TAK 208.00\n",
      "HOUSE RENT ALLOWANCE 1202.00\n",
      "CONVEYANCE ALLOWANCE 1B7aD0\n",
      "EDUCATION tor0D\n",
      "LEAVE TRAVEL ALLOWANCE zebtee\n",
      "AMEDITAL ALLOWANCE 1236.68\n",
      "‘VEAL ALLUWANGE 2184,00\n",
      "SUPPLEMENTARY ALLOWANCE baattod\n",
      "Bross Amsunt 67877.06 | ‘Teta Deduttion 2be08\n",
      "Ret Satsry if arent\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import img_2_txt as cvrt\n",
    "\n",
    "txt = cvrt.txt_from_img(img)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OME ECE ‘OMTECH CHEMICAL INDUSTRIES PVT. LTD.\n",
      "\n",
      "PayStip e Payalip for the month : December 2018 Branel ANDHERI\n",
      "\n",
      "EmpCode:  TOM02, Name Mr. VIRENDRA VITHAL KOLBEKAR Basle: 12760.00\n",
      "\n",
      "Grade A Dopartment : EXPORT Designation: EXPORT EXECUTIVE\n",
      "\n",
      "ESIC Ne. VAN No. : 100409628642 Division :\n",
      "\n",
      "Joining Dt. 1042018\n",
      "\n",
      "Days Pald = 28.00 Days Present: 23.00 WOMPdOn: — 4.0070.00 LWPiAbsent: 0.007300\n",
      "\n",
      "si 100 cL: 00 PL 0.00 co+ico 0.00 10.00\n",
      "\n",
      "Bal Su: 0.00 Bal. cL: 9.90 Bal. PL: 4.00 Bal. CO: 0.00\n",
      "\n",
      "Earnings & Reimbursements Gross Amt Actual Amt [Deductions & Recoveries Gross Amt Actual Amt\n",
      "\n",
      "‘Eamed Basic 12780.00 +4816.00\" | PROV, FUND 1599.00 1382.00\n",
      "\n",
      "HRA 7275.00 6571.00 | P.Tax 0.00 200.00\n",
      "\n",
      "Transport Allowance 6275.00 5868.00\n",
      "\n",
      "Total Earnings 2630.00 28765.00 | Total Deductions: 1582.00\n",
      "Nat Pa 2273.00\n",
      "\n",
      "‘Net Pay: Rupees Twenty Two Thousand One Hundred Seventy Three Only\n",
      "Bank Name: BANK OF INDIA. Bank Ale No. 0161010000531 1\n",
      "Checked by: Approved by: Received by:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "# Read image to convert image to string\n",
    "img = cv2.imread('Images/1.png')\n",
    " \n",
    "# Resize the image if required\n",
    "height, width, channel = img.shape\n",
    "# images = cv2.resize(img, (width//2, height//2))\n",
    " \n",
    "# Convert to grayscale image\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Converting grey image to binary image by Thresholding\n",
    "thresh_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    " \n",
    "# configuring parameters for tesseract\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    " \n",
    "# Converting image to text with pytesseract\n",
    "ocr_output = pytesseract.image_to_string(thresh_img)\n",
    "# Print output text from OCR\n",
    "print(ocr_output)\n",
    " \n",
    "# Writing OCR output to a text file\n",
    "with open('python_ocr_output.txt', 'w') as f:\n",
    "    f.write(ocr_output)\n",
    " \n",
    "# Display image\n",
    "cv2.imshow('Gray image', images)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "import cv2  # import OpenCV library\n",
    " \n",
    "# Read image for contour detection\n",
    "input_image = cv2.imread(\"Images/1.png\")\n",
    " \n",
    "# Make a copy to draw bounding box\n",
    "input_image_cpy = input_image.copy()\n",
    " \n",
    "# Show input image in OpenCV\n",
    "cv2.imshow('Input image', input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Convert input image to grayscale\n",
    "gray_img = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Show grey image in OpenCV\n",
    "cv2.imshow('Grey image', gray_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "threshold_value = gray_img[216, 402]\n",
    "print(threshold_value)\n",
    " \n",
    "# Convert the grayscale image to binary (image binarization opencv python)\n",
    "ret, binary_img = cv2.threshold(gray_img, threshold_value, 255, cv2.THRESH_BINARY)\n",
    " \n",
    "# Show binary image in OpenCV\n",
    "cv2.imshow('Binary image', binary_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Invert image\n",
    "inverted_binary_img = ~ binary_img\n",
    " \n",
    "# Show binary image in OpenCV\n",
    "cv2.imshow('Inverted image', inverted_binary_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Detect contours\n",
    "# hierarchy variable contains information about the relationship between each contours\n",
    "contours_list, hierarchy = cv2.findContours(inverted_binary_img,\n",
    "                                       cv2.RETR_TREE,\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE) # Find contours\n",
    " \n",
    "# Draw first contour\n",
    "first_contour = 0\n",
    "second_contour = 1\n",
    " \n",
    "contour1 = cv2.drawContours(input_image, contours_list, first_contour,(255,0,255),3)\n",
    "cv2.imshow('First detected contour', contour1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Draw a bounding box around the first contour\n",
    "x, y, w, h = cv2.boundingRect(contours_list[first_contour])\n",
    "cv2.rectangle(contour1,(x,y), (x+w,y+h), (0,0,255), 5)\n",
    "cv2.imshow('First contour with bounding box', contour1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Draw a bounding box around all detected contours\n",
    "for c in contours_list:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    " \n",
    "    # Make sure contour area is large enough\n",
    "    if (cv2.contourArea(c)) > 1000:\n",
    "        cv2.rectangle(input_image_cpy, (x, y), (x + w, y + h), (0, 0, 255), 5)\n",
    " \n",
    "cv2.imshow('All contours with bounding box', input_image_cpy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of boxes:  160\n",
      "dict_keys(['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "# Import OpenCV library\n",
    "import cv2\n",
    " \n",
    "import csv\n",
    " \n",
    "# Read image to extract text from image\n",
    "img = cv2.imread('Images/2.png')\n",
    "# Resize the image if required\n",
    "height, width, channel = img.shape\n",
    "# img = cv2.resize(img, (width//2, height//2))\n",
    " \n",
    "# Convert image to grey scale\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Converting grey image to binary image by Thresholding\n",
    "thresh_img = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    " \n",
    "# configuring parameters for tesseract\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    " \n",
    "# Get all OCR output information from pytesseract\n",
    "ocr_output_details = pytesseract.image_to_data(thresh_img, output_type = Output.DICT, config=custom_config, lang='eng')\n",
    "# Total bounding boxes\n",
    "n_boxes = len(ocr_output_details['level'])\n",
    "print(\"No. of boxes: \", n_boxes)\n",
    " \n",
    "# Extract and draw rectangles for all bounding boxes\n",
    "for i in range(n_boxes):\n",
    "    (x, y, w, h) = (ocr_output_details['left'][i], ocr_output_details['top'][i], ocr_output_details['width'][i], ocr_output_details['height'][i])\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    " \n",
    "# Print OCR Output kesys\n",
    "print(ocr_output_details.keys())\n",
    " \n",
    "# Show output image with bounding boxes\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', 'PP', 'Sutury', '(KP', '', '.', 'Hf', 'i', '', 'FL', 'HOME', 'FINANCE', 'LIMITED', '', '1IFL', 'PAYSLIP', 'FOR', 'THE', 'MONTH', 'OF', 'OCT', '2018', '', '-', '—————', '', 'Employee', 'Name', 'PRASHANT', 'RANJITKUMAR', 'SABUWALA', 'Employee', 'Code.', '146235', '', 'Designation', 'SALES', 'MANAGER', 'Location', 'SURAT', '', 'Department', 'SALES', 'doin', 'Date', '26/07/2016', '', 'PAN', 'Number', 'ASUPS4860J', 'PF', 'account', 'No.', '0', '', 'Branch', 'SURAT-RING', 'ROAD', 'Bank', 'Acc.', 'No.', '02511050095925', '', 'Bank', 'Name', 'HDFG', 'Grade', 'MANAGER', '', 'No.', 'Of', 'Working', 'Days', '30.50', 'Leave', 'Taken', '00.00', '', 'UAN', 'NO', 'Lwe', '00.50', '', 'ESIC', 'NO', '', '[aan', 'rections', '', 'BASIC', 'SALARY', '24004.00', '|', 'PROFESSION', 'TAX', '200.00', '', 'HOUSE', 'RENT', 'ALLOWANCE', '12002.00', '', 'CONVEYANCE', 'ALLOWANCE', '1874.00', '', 'EDUCATION', '197.00', '', 'px)', 'LEAVE', 'TRAVEL', 'ALLOWANCE', '2000.00', '', 'MEDICAL', 'ALLOWANCE', '1230.00', '', 'MEAL', 'ALLOWANCE', '2164.00', '', 'SUPPLEMENTARY', 'ALLOWANCE', '24408.00', '', 'In', 'Words', ':', 'Rupees', 'Sixty-Seven', 'Thousand', 'Three', 'Hundred', 'Seventy-Seven', 'only', '.', '', '\\\\Note', ':', 'Since', 'this', 'is', 'a', 'computer-generated', 'statement,', 'il', 'does', 'not', 'need', 'any', 'signature.', '', '=)', '¢', 'Bene']\n",
      "[-1, -1, -1, -1, 38, 20, 31, -1, 25, 30, 50, -1, 8, 84, 96, 96, -1, 52, 87, 96, 96, 96, 92, 87, 92, -1, 14, 7, -1, 95, 96, 93, 90, 92, 50, 64, 42, -1, 94, 96, 96, 92, 94, -1, 86, 96, 53, 92, 80, -1, 96, 95, 71, 96, 83, 95, 50, -1, 96, 70, 96, 96, 85, 95, 69, -1, 96, 78, 45, 91, 96, -1, 94, 96, 96, 94, 92, 96, 94, 79, -1, 90, 95, 70, 70, -1, 81, 90, -1, 35, 29, -1, 90, 96, 76, 93, 91, 92, 82, -1, 96, 96, 96, 88, -1, 95, 95, 85, -1, 96, 81, -1, 5, 48, 96, 91, 95, -1, 96, 96, 94, -1, 94, 95, 78, -1, 84, 89, 57, -1, 96, 90, 92, 93, 89, 96, 94, 90, 90, 91, 26, -1, 69, 88, 96, 92, 96, 84, 84, 95, 81, 93, 95, 86, 96, 87, -1, 50, 72, 22]\n"
     ]
    }
   ],
   "source": [
    "print(ocr_output_details[\"text\"])\n",
    "print(ocr_output_details[\"conf\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
